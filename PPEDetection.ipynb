{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258abb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#go into the folder you want, initialize an empty repo\n",
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the files you want to push. Use add . if you wanna add all the files.\n",
    "!git add PPEDetection.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ppe.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commit all the files you have added. Also write down a message\n",
    "!git commit -m \"first commit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a branch called main\n",
    "!git branch -M main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote add origin into the github repo you want.\n",
    "!git remote add origin https://github.com/Ngonidzashe-ux/PPEDetectionSystem.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Push the changes to the main branch\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12361ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the status of your commits\n",
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b1411",
   "metadata": {},
   "source": [
    "## 1. Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bedc9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import math\n",
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f90a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our YOLO instance by passing in the custom trained model.\n",
    "model = YOLO('ppe.pt')\n",
    "classNames = ['Excavator', 'Gloves', 'Hardhat', 'Ladder', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'SUV', 'Safety Cone', 'Safety Vest', 'bus', 'dump truck', 'fire hydrant', 'machinery', 'mini-van', 'sedan', 'semi', 'trailer', 'truck and trailer', 'truck', 'van', 'vehicle', 'wheel loader']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65766301",
   "metadata": {},
   "source": [
    "## 2. Define Model Instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a47807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "877 578 1787 2155\n",
      "1601 81 2481 2160\n",
      "1076 1105 1651 2157\n",
      "1224 576 1592 812\n",
      "1922 89 2276 341\n",
      "1989 445 2175 566\n",
      "2352 946 3049 2155\n",
      "2506 478 2905 713\n",
      "2604 765 2790 890\n",
      "1310 985 1500 1110\n",
      "1741 571 2391 2151\n",
      "2297 463 3118 2157\n",
      "1572 1953 1725 2157\n",
      "1743 572 2384 1633\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 4 NO-Safety Vests, 3 Persons, 640.6ms\n",
      "Speed: 7.4ms preprocess, 640.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "883 577 1798 2154\n",
      "1602 81 2496 2157\n",
      "1068 1105 1657 2158\n",
      "1225 576 1594 812\n",
      "1950 89 2305 344\n",
      "2514 474 2913 708\n",
      "2356 942 3065 2149\n",
      "1754 570 2398 1511\n",
      "2012 445 2199 562\n",
      "1312 987 1507 1112\n",
      "2607 764 2794 888\n",
      "2224 466 3126 2155\n",
      "1753 568 2403 2108\n",
      "1569 1947 1729 2157\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 4 NO-Safety Vests, 3 Persons, 518.7ms\n",
      "Speed: 2.5ms preprocess, 518.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1611 90 2510 2154\n",
      "883 576 1828 2154\n",
      "1067 1106 1651 2159\n",
      "2033 444 2221 567\n",
      "1972 91 2326 345\n",
      "1224 577 1595 812\n",
      "2520 474 2914 705\n",
      "2378 942 3076 2150\n",
      "2286 470 3130 2155\n",
      "1310 992 1503 1113\n",
      "1750 568 2426 2152\n",
      "2611 762 2800 890\n",
      "1568 1942 1729 2157\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 505.1ms\n",
      "Speed: 2.0ms preprocess, 505.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1622 93 2518 2154\n",
      "883 576 1856 2153\n",
      "1063 1098 1666 2159\n",
      "1219 577 1590 819\n",
      "1995 94 2354 347\n",
      "2525 474 2920 696\n",
      "2404 941 3080 2149\n",
      "2054 448 2244 569\n",
      "1314 991 1511 1114\n",
      "1760 564 2435 2154\n",
      "2617 761 2816 891\n",
      "2322 461 3139 2155\n",
      "1576 1938 1736 2158\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 492.9ms\n",
      "Speed: 2.2ms preprocess, 492.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1631 98 2537 2152\n",
      "888 580 1798 2153\n",
      "1047 1084 1668 2157\n",
      "1214 579 1604 828\n",
      "2019 99 2376 349\n",
      "2540 477 2939 701\n",
      "2084 445 2283 572\n",
      "2419 935 3074 1953\n",
      "1322 990 1529 1119\n",
      "2325 461 3152 2152\n",
      "2628 771 2827 900\n",
      "1590 1926 1738 2158\n",
      "1787 570 2432 1490\n",
      "1774 568 2461 2122\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 4 NO-Safety Vests, 3 Persons, 522.5ms\n",
      "Speed: 2.2ms preprocess, 522.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "893 580 1797 2152\n",
      "1646 94 2546 2156\n",
      "1039 1083 1688 2158\n",
      "2043 100 2422 354\n",
      "1809 576 2465 1442\n",
      "1199 580 1615 846\n",
      "1339 993 1534 1116\n",
      "2573 482 2958 732\n",
      "2434 941 3081 1977\n",
      "2118 449 2314 570\n",
      "2641 779 2837 904\n",
      "2346 483 3165 2158\n",
      "1596 1922 1748 2158\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 510.1ms\n",
      "Speed: 2.2ms preprocess, 510.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "888 581 1799 2153\n",
      "1653 98 2551 2156\n",
      "1030 1085 1701 2157\n",
      "1191 579 1617 866\n",
      "1833 578 2482 1386\n",
      "2061 105 2457 361\n",
      "2603 487 2973 726\n",
      "2424 959 3097 2068\n",
      "1612 1921 1756 2158\n",
      "2143 454 2343 575\n",
      "2357 482 3171 2155\n",
      "2662 792 2852 912\n",
      "1359 1006 1529 1114\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 495.7ms\n",
      "Speed: 1.9ms preprocess, 495.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "881 583 1796 2153\n",
      "1661 101 2559 2160\n",
      "1026 1083 1693 2157\n",
      "1182 582 1625 873\n",
      "2068 109 2487 350\n",
      "2629 490 2993 728\n",
      "2438 971 3121 2097\n",
      "2149 456 2368 572\n",
      "2343 483 3193 2158\n",
      "1814 580 2511 2150\n",
      "2674 800 2865 916\n",
      "1381 1008 1530 1113\n",
      "1621 1897 1760 2156\n",
      "1237 993 1537 1120\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 4 NO-Masks, 3 NO-Safety Vests, 3 Persons, 500.2ms\n",
      "Speed: 2.1ms preprocess, 500.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1672 100 2570 2160\n",
      "871 585 1791 2153\n",
      "1026 1078 1676 2155\n",
      "1181 584 1635 886\n",
      "1827 580 2534 2149\n",
      "2083 110 2510 392\n",
      "2640 491 3016 734\n",
      "2493 979 3136 2140\n",
      "2695 807 2884 925\n",
      "2182 454 2391 570\n",
      "2358 484 3215 2160\n",
      "1384 1008 1535 1110\n",
      "1617 1885 1761 2157\n",
      "1270 996 1541 1110\n",
      "870 1819 938 1909\n",
      "0: 384x640 2 Glovess, 3 Hardhats, 4 NO-Masks, 3 NO-Safety Vests, 3 Persons, 515.0ms\n",
      "Speed: 2.0ms preprocess, 515.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1684 103 2585 2160\n",
      "872 588 1785 2154\n",
      "1170 588 1634 896\n",
      "1023 1068 1663 2154\n",
      "2089 110 2522 407\n",
      "2669 490 3042 735\n",
      "1834 577 2534 2149\n",
      "2511 976 3163 2139\n",
      "2394 474 3251 2156\n",
      "1401 1009 1541 1110\n",
      "2717 810 2914 924\n",
      "2192 449 2411 577\n",
      "1589 1885 1756 2157\n",
      "894 1936 1023 2155\n",
      "0: 384x640 2 Glovess, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 524.5ms\n",
      "Speed: 2.0ms preprocess, 524.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1693 104 2590 2160\n",
      "854 592 1775 2155\n",
      "1152 591 1627 910\n",
      "2092 111 2532 411\n",
      "1012 1078 1653 2155\n",
      "2532 982 3180 2146\n",
      "1849 579 2531 2149\n",
      "2672 484 3073 743\n",
      "2460 476 3278 2153\n",
      "2742 806 2930 924\n",
      "1414 1009 1540 1110\n",
      "2204 451 2417 573\n",
      "1572 1882 1748 2157\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 545.1ms\n",
      "Speed: 2.4ms preprocess, 545.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1694 110 2598 2160\n",
      "816 592 1752 2160\n",
      "979 1075 1648 2156\n",
      "2093 114 2532 418\n",
      "1124 596 1615 920\n",
      "2563 985 3193 2146\n",
      "1847 589 2526 1813\n",
      "2483 479 3300 2156\n",
      "2681 482 3098 756\n",
      "2757 800 2946 914\n",
      "1398 1010 1529 1111\n",
      "2221 453 2422 570\n",
      "1584 1882 1734 2158\n",
      "853 1955 1000 2158\n",
      "0: 384x640 2 Glovess, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 595.5ms\n",
      "Speed: 2.0ms preprocess, 595.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1691 118 2599 2160\n",
      "1114 596 1589 921\n",
      "802 591 1728 2159\n",
      "2094 120 2533 426\n",
      "2496 476 3325 2156\n",
      "970 1075 1636 2155\n",
      "2595 983 3206 2157\n",
      "1845 592 2529 1822\n",
      "2731 478 3124 762\n",
      "2772 797 2949 903\n",
      "2223 461 2420 577\n",
      "1368 1001 1525 1108\n",
      "824 1961 957 2159\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 565.4ms\n",
      "Speed: 2.1ms preprocess, 565.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1689 125 2606 2160\n",
      "957 1070 1613 2156\n",
      "1090 590 1575 911\n",
      "2525 468 3362 2152\n",
      "782 588 1715 2158\n",
      "2097 130 2530 419\n",
      "1842 589 2534 1801\n",
      "2614 972 3226 2156\n",
      "2744 473 3155 774\n",
      "1381 1004 1500 1100\n",
      "2779 773 2961 890\n",
      "2222 475 2419 589\n",
      "808 1978 947 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 554.6ms\n",
      "Speed: 2.1ms preprocess, 554.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1685 137 2616 2160\n",
      "1066 580 1554 909\n",
      "940 1063 1601 2156\n",
      "2093 135 2526 441\n",
      "1842 586 2536 1771\n",
      "765 580 1699 2157\n",
      "2538 467 3392 2156\n",
      "2646 963 3262 2156\n",
      "2774 465 3183 778\n",
      "2790 751 2981 872\n",
      "1339 995 1478 1091\n",
      "2216 483 2416 594\n",
      "781 1984 931 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 543.0ms\n",
      "Speed: 2.1ms preprocess, 543.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1680 142 2614 2159\n",
      "710 568 1659 2155\n",
      "934 1056 1580 2156\n",
      "2546 456 3396 2148\n",
      "1042 569 1530 907\n",
      "2089 141 2522 443\n",
      "1839 589 2533 1739\n",
      "2656 958 3270 2146\n",
      "2783 458 3203 778\n",
      "2801 736 3003 866\n",
      "2210 492 2412 600\n",
      "1318 982 1461 1078\n",
      "761 2000 905 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 538.8ms\n",
      "Speed: 2.1ms preprocess, 538.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1675 146 2608 2160\n",
      "2080 147 2514 438\n",
      "1016 556 1507 900\n",
      "2665 955 3271 2135\n",
      "691 551 1649 2152\n",
      "1833 594 2520 1761\n",
      "2557 450 3431 2151\n",
      "930 1063 1565 2154\n",
      "2804 454 3217 770\n",
      "2813 720 3016 860\n",
      "2216 495 2407 603\n",
      "1301 959 1443 1065\n",
      "742 2004 886 2160\n",
      "1258 950 1445 1069\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 4 NO-Masks, 3 NO-Safety Vests, 3 Persons, 569.3ms\n",
      "Speed: 2.2ms preprocess, 569.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1668 146 2601 2159\n",
      "2072 148 2512 443\n",
      "993 553 1479 903\n",
      "2572 445 3448 2148\n",
      "1830 578 2500 1764\n",
      "911 1065 1556 2154\n",
      "671 552 1647 2154\n",
      "2818 452 3227 772\n",
      "2828 724 3027 856\n",
      "2701 950 3304 2010\n",
      "1280 939 1434 1052\n",
      "2217 500 2401 608\n",
      "730 2019 867 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 564.6ms\n",
      "Speed: 2.8ms preprocess, 564.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "2061 146 2506 447\n",
      "1661 145 2598 2159\n",
      "2568 438 3466 2150\n",
      "973 551 1444 906\n",
      "889 1048 1536 2156\n",
      "666 546 1643 2153\n",
      "2713 946 3308 1755\n",
      "1824 583 2499 1800\n",
      "2836 706 3043 851\n",
      "2827 448 3243 767\n",
      "2211 500 2394 605\n",
      "1292 946 1416 1042\n",
      "719 2026 858 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 551.1ms\n",
      "Speed: 2.2ms preprocess, 551.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1649 144 2593 2157\n",
      "2049 142 2495 442\n",
      "875 1046 1528 2157\n",
      "660 547 1628 2153\n",
      "1814 578 2496 1794\n",
      "947 551 1410 910\n",
      "2563 429 3483 2155\n",
      "2846 707 3057 849\n",
      "2701 941 3307 2155\n",
      "2831 444 3256 769\n",
      "1271 917 1404 1032\n",
      "2187 495 2377 599\n",
      "711 2032 850 2159\n",
      "1470 1876 1623 2157\n",
      "0: 384x640 2 Glovess, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 700.7ms\n",
      "Speed: 2.2ms preprocess, 700.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1637 134 2592 2160\n",
      "864 1043 1510 2157\n",
      "925 550 1385 915\n",
      "1804 594 2489 1820\n",
      "2032 138 2478 430\n",
      "2560 426 3482 2156\n",
      "653 543 1624 2152\n",
      "2699 940 3312 2158\n",
      "2832 440 3255 752\n",
      "2849 717 3061 849\n",
      "1270 916 1388 1021\n",
      "2175 490 2367 590\n",
      "704 2034 849 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 618.5ms\n",
      "Speed: 2.3ms preprocess, 618.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1622 125 2575 2160\n",
      "655 535 1616 2151\n",
      "2560 428 3477 2159\n",
      "902 544 1315 912\n",
      "1792 584 2482 2011\n",
      "874 1040 1499 2149\n",
      "2012 129 2451 423\n",
      "2832 435 3255 749\n",
      "2692 934 3317 2149\n",
      "2848 716 3065 850\n",
      "1237 898 1369 1016\n",
      "2162 486 2348 591\n",
      "702 2027 854 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 610.5ms\n",
      "Speed: 2.5ms preprocess, 610.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "1610 119 2561 2160\n",
      "657 532 1610 2152\n",
      "890 541 1298 910\n",
      "2563 428 3469 2160\n",
      "863 1033 1488 2153\n",
      "1998 119 2443 421\n",
      "1782 578 2489 2150\n",
      "2680 936 3320 2148\n",
      "2834 435 3260 744\n",
      "2853 721 3070 855\n",
      "1232 905 1355 1004\n",
      "2144 473 2337 586\n",
      "714 2019 872 2160\n",
      "0: 384x640 1 Gloves, 3 Hardhats, 3 NO-Masks, 3 NO-Safety Vests, 3 Persons, 641.2ms\n",
      "Speed: 2.4ms preprocess, 641.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a webcam object\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Pass a video\n",
    "cap = cv2.VideoCapture('../Videos/ppe2.mov')\n",
    "\n",
    "myColor = (0,0,255) #Blue\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #read a frame and pass it into the model\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            \n",
    "            #Get the coordinates of the 4 corners of the box\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            \n",
    "            #convert the coordinates from tensor type to int type\n",
    "            x1,x2,y1,y2 =int(x1),int(x2),int(y1),int(y2)\n",
    "            \n",
    "            #debugging\n",
    "            print(x1,y1,x2, y2)\n",
    "            \n",
    "            #x1,y1,w,h\n",
    "            bbox = x1,y1, x2-x1, y2-y1\n",
    "            \n",
    "            #Confidence value that is in the tensor type and we round it up to the ceil and express in 2 dp\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "            \n",
    "            cls = int(box.cls[0])\n",
    "            currentClass = classNames[cls]\n",
    "            if conf > 0.5:\n",
    "                if currentClass == 'NO-Hardhat' or currentClass == 'NO-Safety Vest' or currentClass == 'NO-Mask' or currentClass == 'NO-Gloves':\n",
    "                    myColor = (0,0,255) #Red\n",
    "                elif currentClass == 'Hardhat' or currentClass == 'Safety Vest' or currentClass == 'Mask' or currentClass == 'Gloves':\n",
    "                    myColor = (0,255,0) #Green\n",
    "                else:\n",
    "                    myColor = (255,0,0) #Blue\n",
    "\n",
    "            #put the classname, label and bounding box\n",
    "            cvzone.putTextRect(img, \"{} {}\".format(classNames[cls], conf), (max(0,x1), max(35,y1)), scale=3.5, offset=5, thickness=1, colorB=myColor, colorT=(255, 255, 255), colorR=myColor)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), myColor, 3)\n",
    "\n",
    "    window_name = \"Image\"\n",
    "    \n",
    "    #display the frame img in a new window labeled 'Image'\n",
    "    cv2.imshow(window_name, img)\n",
    "    \n",
    "    #move the window to my primary monitor\n",
    "    cv2.moveWindow(window_name, 0, 0)\n",
    "     \n",
    "    #Removes window 2s after key pressing\n",
    "    cv2.waitKey(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe196fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
